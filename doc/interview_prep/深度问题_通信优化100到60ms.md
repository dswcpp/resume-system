# 深度问题：通信优化100ms到60ms

> 简历原文：优化硬件驱动与上层应用通信机制，系统响应时间从100ms优化至60ms

---

## 一、背景说明

### 1.1 项目场景

柜外交互终端，需要对接多种外设：
- 密码键盘
- IC卡读卡器
- 二代证阅读器
- 电磁签名板
- ...

每个外设都有自己的驱动程序，上层应用需要和这些驱动通信。

### 1.2 通信架构

```
┌─────────────────────────────────────────┐
│              上层应用                    │
│         (业务逻辑、UI)                   │
└───────────────┬─────────────────────────┘
                │ 进程间通信
┌───────────────▼─────────────────────────┐
│            中转服务                      │
│      (协议转换、路由分发)                │
└───────────────┬─────────────────────────┘
                │ 驱动API调用
┌───────────────▼─────────────────────────┐
│           硬件驱动层                     │
│    (各厂商提供的DLL)                     │
└───────────────┬─────────────────────────┘
                │ USB/串口
┌───────────────▼─────────────────────────┐
│            硬件设备                      │
└─────────────────────────────────────────┘
```

### 1.3 问题描述

用户反馈：刷IC卡后，屏幕显示慢。

测量：从刷卡到界面显示，平均100ms，有时候150ms+。

目标：优化到60ms以内。

---

## 二、问题定位

### 2.1 测量方法

在关键节点打时间戳：

```cpp
void onCardSwipe() {
    auto t0 = now();  // 驱动回调时间
    
    // 发送给中转服务
    sendToService(data);
    auto t1 = now();  // 发送完成时间
    
    // 等待响应
    auto response = waitResponse();
    auto t2 = now();  // 收到响应时间
    
    // 更新UI
    updateUI(response);
    auto t3 = now();  // UI更新完成时间
    
    log(t0, t1, t2, t3);
}
```

### 2.2 分析结果

| 阶段 | 耗时 | 说明 |
|------|------|------|
| 驱动回调 | 5ms | 硬件响应，无法优化 |
| 数据序列化 | 15ms | JSON序列化 |
| 进程间通信 | 30ms | Socket通信 |
| 中转服务处理 | 20ms | 协议转换 |
| 响应等待 | 20ms | 同步等待 |
| UI更新 | 10ms | 界面刷新 |
| **总计** | **100ms** | |

瓶颈在于：
1. **进程间通信**：30ms太长
2. **同步等待**：完全阻塞

---

## 三、优化方案

### 3.1 通信协议优化

#### 原方案：JSON over TCP

```cpp
// 原来的协议
{
    "type": "card_read",
    "device": "ic_card_reader",
    "data": {
        "card_no": "6225xxxx",
        "card_type": "debit",
        "bank": "ICBC"
    },
    "timestamp": 1635123456789
}
```

问题：
- JSON解析慢（字符串处理）
- 数据量大（字段名重复）

#### 优化方案：二进制协议

```cpp
// 定义紧凑的二进制格式
#pragma pack(push, 1)
struct CardReadMessage {
    uint16_t type;       // 消息类型
    uint16_t deviceId;   // 设备ID
    int64_t timestamp;   // 时间戳
    uint8_t cardNo[20];  // 卡号
    uint8_t cardType;    // 卡类型
    uint8_t reserved[3]; // 对齐
};
#pragma pack(pop)

// 序列化就是直接memcpy
void serialize(const CardReadMessage& msg, std::vector<uint8_t>& buffer) {
    buffer.resize(sizeof(msg));
    memcpy(buffer.data(), &msg, sizeof(msg));
}

// 反序列化也是直接memcpy
void deserialize(const std::vector<uint8_t>& buffer, CardReadMessage& msg) {
    memcpy(&msg, buffer.data(), sizeof(msg));
}
```

效果：
| 指标 | JSON | 二进制 |
|------|------|--------|
| 序列化耗时 | 15ms | 0.1ms |
| 消息大小 | 200B | 40B |

### 3.2 通信方式优化

#### 原方案：TCP Socket

```cpp
// 每次通信都是：连接→发送→接收→断开
void sendMessage(const Message& msg) {
    Socket socket;
    socket.connect(SERVER_IP, SERVER_PORT);  // 建立连接
    socket.send(serialize(msg));              // 发送
    auto response = socket.receive();         // 等待响应
    socket.close();                           // 断开
    return deserialize(response);
}
```

问题：
- TCP建立连接需要三次握手，耗时
- 每次都新建连接，效率低

#### 优化方案1：连接池 + 长连接

```cpp
class ConnectionPool {
    std::vector<std::unique_ptr<Socket>> connections_;
    std::mutex mutex_;
    
public:
    Socket* acquire() {
        std::lock_guard<std::mutex> lock(mutex_);
        for (auto& conn : connections_) {
            if (conn->isIdle()) {
                conn->setIdle(false);
                return conn.get();
            }
        }
        // 池里没有空闲连接，创建新的
        auto newConn = std::make_unique<Socket>();
        newConn->connect(SERVER_IP, SERVER_PORT);
        connections_.push_back(std::move(newConn));
        return connections_.back().get();
    }
    
    void release(Socket* socket) {
        std::lock_guard<std::mutex> lock(mutex_);
        socket->setIdle(true);
    }
};

// 使用
void sendMessage(const Message& msg) {
    auto socket = pool.acquire();
    socket->send(serialize(msg));
    auto response = socket->receive();
    pool.release(socket);
    return deserialize(response);
}
```

#### 优化方案2：共享内存（同机通信）

```cpp
// 如果应用和中转服务在同一台机器，用共享内存更快
class SharedMemoryChannel {
    HANDLE hMapFile_;
    void* pBuffer_;
    HANDLE hEventWrite_;  // 写完成事件
    HANDLE hEventRead_;   // 读完成事件
    
public:
    void send(const void* data, size_t len) {
        memcpy(pBuffer_, data, len);
        SetEvent(hEventWrite_);   // 通知对方
        WaitForSingleObject(hEventRead_, INFINITE);  // 等待响应
    }
    
    void receive(void* data, size_t maxLen) {
        WaitForSingleObject(hEventWrite_, INFINITE);
        memcpy(data, pBuffer_, maxLen);
        SetEvent(hEventRead_);
    }
};
```

效果：
| 方式 | 延迟 |
|------|------|
| TCP每次新建连接 | 30ms |
| TCP连接池 | 5ms |
| 共享内存 | 0.5ms |

### 3.3 异步化改造

#### 原方案：同步等待

```cpp
void onCardSwipe(const CardData& data) {
    // 同步调用，阻塞等待
    auto result = service.processCard(data);  // 等待50ms
    updateUI(result);
}
```

问题：UI线程被阻塞50ms，界面卡顿。

#### 优化方案：异步回调

```cpp
void onCardSwipe(const CardData& data) {
    // 立即返回，不阻塞
    service.processCardAsync(data, [this](const Result& result) {
        // 回调在UI线程执行
        QMetaObject::invokeMethod(this, [=]() {
            updateUI(result);
        }, Qt::QueuedConnection);
    });
    
    // 同时可以显示"处理中..."
    showProcessingIndicator();
}
```

进一步优化：预测性UI更新

```cpp
void onCardSwipe(const CardData& data) {
    // 乐观更新：先显示卡号
    ui.showCardNumber(data.cardNo);
    
    // 异步获取详细信息
    service.getCardDetailAsync(data.cardNo, [this](const Detail& detail) {
        QMetaObject::invokeMethod(this, [=]() {
            ui.showCardDetail(detail);
        }, Qt::QueuedConnection);
    });
}
```

### 3.4 驱动调用优化

#### 原方案：每次调用都初始化

```cpp
void readCard() {
    // 每次都初始化驱动
    ICCardDriver driver;
    driver.init();         // 10ms
    driver.connect();      // 20ms
    auto data = driver.read();
    driver.disconnect();
    driver.deinit();
}
```

#### 优化方案：驱动保持连接

```cpp
class CardReaderManager {
    std::unique_ptr<ICCardDriver> driver_;
    bool initialized_ = false;
    
public:
    void ensureInitialized() {
        if (!initialized_) {
            driver_ = std::make_unique<ICCardDriver>();
            driver_->init();
            driver_->connect();
            initialized_ = true;
        }
    }
    
    CardData readCard() {
        ensureInitialized();
        return driver_->read();  // 直接读，无需初始化
    }
    
    // 定期检查连接状态
    void healthCheck() {
        if (initialized_ && !driver_->isConnected()) {
            initialized_ = false;
        }
    }
};
```

---

## 四、优化结果

### 4.1 各阶段耗时对比

| 阶段 | 优化前 | 优化后 | 优化措施 |
|------|--------|--------|----------|
| 驱动回调 | 5ms | 5ms | 无法优化 |
| 数据序列化 | 15ms | 0.1ms | 二进制协议 |
| 进程间通信 | 30ms | 0.5ms | 共享内存 |
| 中转服务处理 | 20ms | 15ms | 代码优化 |
| 响应等待 | 20ms | 0ms | 异步化 |
| UI更新 | 10ms | 10ms | 无变化 |
| **感知延迟** | **100ms** | **30ms** | |

### 4.2 用户感知

- 优化前：刷卡后明显等待，能感觉到"卡"
- 优化后：刷卡后几乎立即显示，流畅

### 4.3 为什么说60ms？

实际总延迟是：5+0.1+0.5+15+10 = 30.6ms

但写简历时考虑到：
1. 现场环境可能有波动
2. 留一些余量
3. 60ms已经是非常好的效果

所以写的是"优化至60ms"，实际更好。

---

## 五、代码示例

### 5.1 共享内存通信完整实现

```cpp
// SharedMemoryChannel.h
class SharedMemoryChannel {
public:
    static const size_t BUFFER_SIZE = 64 * 1024;  // 64KB
    
    struct Header {
        uint32_t magic;      // 魔数，校验用
        uint32_t length;     // 数据长度
        uint32_t sequence;   // 序列号
    };
    
    bool create(const std::string& name);
    bool open(const std::string& name);
    void close();
    
    bool send(const void* data, size_t len, uint32_t timeoutMs = 1000);
    bool receive(void* data, size_t maxLen, size_t& actualLen, uint32_t timeoutMs = 1000);
    
private:
    HANDLE hMapFile_ = nullptr;
    void* pBuffer_ = nullptr;
    HANDLE hMutex_ = nullptr;
    HANDLE hEventReady_ = nullptr;
    HANDLE hEventDone_ = nullptr;
};

// SharedMemoryChannel.cpp
bool SharedMemoryChannel::create(const std::string& name) {
    // 创建共享内存
    hMapFile_ = CreateFileMappingA(
        INVALID_HANDLE_VALUE,
        nullptr,
        PAGE_READWRITE,
        0,
        sizeof(Header) + BUFFER_SIZE,
        name.c_str()
    );
    if (!hMapFile_) return false;
    
    pBuffer_ = MapViewOfFile(hMapFile_, FILE_MAP_ALL_ACCESS, 0, 0, 0);
    if (!pBuffer_) return false;
    
    // 创建同步对象
    hMutex_ = CreateMutexA(nullptr, FALSE, (name + "_mutex").c_str());
    hEventReady_ = CreateEventA(nullptr, FALSE, FALSE, (name + "_ready").c_str());
    hEventDone_ = CreateEventA(nullptr, FALSE, FALSE, (name + "_done").c_str());
    
    return true;
}

bool SharedMemoryChannel::send(const void* data, size_t len, uint32_t timeoutMs) {
    // 加锁
    WaitForSingleObject(hMutex_, INFINITE);
    
    // 写数据
    auto header = static_cast<Header*>(pBuffer_);
    header->magic = 0xDEADBEEF;
    header->length = static_cast<uint32_t>(len);
    header->sequence++;
    
    memcpy(static_cast<char*>(pBuffer_) + sizeof(Header), data, len);
    
    // 通知对方
    SetEvent(hEventReady_);
    
    // 等待对方处理完
    DWORD result = WaitForSingleObject(hEventDone_, timeoutMs);
    
    ReleaseMutex(hMutex_);
    
    return result == WAIT_OBJECT_0;
}
```

### 5.2 异步服务调用

```cpp
class AsyncServiceClient {
    SharedMemoryChannel channel_;
    std::thread workerThread_;
    std::queue<std::pair<Request, Callback>> pendingRequests_;
    std::mutex mutex_;
    std::condition_variable cv_;
    
public:
    using Callback = std::function<void(const Response&)>;
    
    void callAsync(const Request& request, Callback callback) {
        {
            std::lock_guard<std::mutex> lock(mutex_);
            pendingRequests_.emplace(request, callback);
        }
        cv_.notify_one();
    }
    
private:
    void workerLoop() {
        while (running_) {
            std::pair<Request, Callback> item;
            {
                std::unique_lock<std::mutex> lock(mutex_);
                cv_.wait(lock, [this]() { 
                    return !pendingRequests_.empty() || !running_; 
                });
                if (!running_) break;
                item = std::move(pendingRequests_.front());
                pendingRequests_.pop();
            }
            
            // 发送请求
            channel_.send(&item.first, sizeof(Request));
            
            // 接收响应
            Response response;
            size_t len;
            channel_.receive(&response, sizeof(Response), len);
            
            // 回调
            item.second(response);
        }
    }
};
```

---

## 六、面试追问准备

### Q1: 为什么选共享内存而不是其他IPC方式？

```
对比各种IPC方式：

| 方式 | 延迟 | 复杂度 | 适用场景 |
|------|------|--------|----------|
| TCP | 高 | 低 | 跨机器 |
| UDP | 中 | 低 | 跨机器、允许丢包 |
| 命名管道 | 中 | 中 | 同机器 |
| 共享内存 | 低 | 高 | 同机器、高性能 |
| 消息队列 | 中 | 中 | 异步场景 |

我们是同机器通信、对延迟敏感，所以选共享内存。
复杂度高的问题通过封装解决。
```

### Q2: 共享内存有什么坑？

```
1. 同步问题
   - 多进程访问需要加锁
   - 要处理进程崩溃时锁未释放的情况
   
2. 内存管理
   - 共享内存里不能放指针（地址在不同进程不同）
   - 只能放plain old data
   
3. 版本兼容
   - 两边的数据结构定义要一致
   - 升级时要考虑兼容性

4. 调试困难
   - 数据是二进制的，不好看
   - 需要专门的调试工具

我们通过定义清晰的协议、添加版本号、写调试工具来解决这些问题。
```

### Q3: 60ms的指标是怎么验证的？

```
验证方法：

1. 代码埋点
   - 关键节点打时间戳
   - 统计P50、P95、P99延迟

2. 外部测量
   - 用高速摄像机拍摄
   - 从刷卡动作到屏幕变化
   
3. 用户反馈
   - 优化前：10%的用户反馈"慢"
   - 优化后：几乎无反馈

实测P95延迟：
- 优化前：120ms
- 优化后：45ms
```

### Q4: 还能继续优化吗？

```
理论上可以，但收益递减：

1. 驱动层（5ms）
   - 换更快的硬件
   - 改驱动代码（需要厂商配合）
   
2. 中转服务（15ms）
   - 进一步优化代码
   - 可能再省5ms

3. UI层（10ms）
   - 用更轻量的控件
   - 预渲染

但现在30ms已经足够好了，用户感知不出差异。
投入产出比不高，不值得继续优化。
```

### Q5: 这个优化对系统其他指标有影响吗？

```
有一些trade-off：

1. CPU占用略增
   - 共享内存需要轮询或事件等待
   - 实测增加2-3%，可接受

2. 内存占用增加
   - 共享内存需要预分配
   - 增加64KB，可忽略

3. 代码复杂度增加
   - 需要处理同步、超时等
   - 通过良好封装控制复杂度

总体是值得的，核心指标（响应时间）提升明显。
```
