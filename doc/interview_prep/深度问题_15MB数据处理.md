# 深度问题：如何做到15MB/s数据处理

> 简历原文：系统可流畅处理15MB/s实时数据流

---

## 一、数据量分析

### 1.1 数据来源

T95终端有多个检测模块，各自的数据量：

| 模块 | 采样率 | 每帧大小 | 数据率 |
|------|--------|----------|--------|
| 红外 | 25Hz | 640×480×2B = 600KB | 15MB/s |
| UHF | 1000Hz | 1024点×2B = 2KB | 2MB/s |
| TEV | 1000Hz | 512点×2B = 1KB | 1MB/s |
| AE | 1000Hz | 1024点×2B = 2KB | 2MB/s |
| **总计** | - | - | **~20MB/s** |

红外模块是大头，单独就15MB/s。

### 1.2 处理流程

```
采集 → 解析 → 处理 → 显示
```

每个环节都要能跟上15MB/s，否则就会卡顿或丢帧。

---

## 二、瓶颈分析

### 2.1 优化前的问题

```cpp
// 问题代码
void onFrameReceived(const uint8_t* data, size_t len) {
    // 1. 数据拷贝（耗时）
    QByteArray buffer(reinterpret_cast<const char*>(data), len);
    
    // 2. 格式转换（耗时）
    QImage image = convertToImage(buffer);
    
    // 3. 直接在回调里更新UI（阻塞采集）
    emit updateDisplay(image);
}
```

问题：
1. **数据拷贝**：600KB/帧，每秒25帧，拷贝开销大
2. **同步处理**：采集回调里做处理，会阻塞下一帧采集
3. **UI阻塞**：信号槽默认同步调用，UI刷新时采集停顿

### 2.2 性能测量

```cpp
// 加时间戳测量
void onFrameReceived(...) {
    auto t1 = std::chrono::high_resolution_clock::now();
    
    // 处理...
    
    auto t2 = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(t2 - t1);
    qDebug() << "Frame processing time:" << duration.count() << "us";
}
```

测量结果：
| 操作 | 耗时 |
|------|------|
| 数据拷贝 | 200μs |
| 格式转换 | 5000μs |
| UI更新 | 10000μs |
| **总计** | **15200μs** |

需要40ms/帧（25Hz），但处理就花了15ms，还没算采集时间。

---

## 三、优化方案

### 3.1 架构设计

```
┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐
│  采集    │ -> │  解析    │ -> │  处理    │ -> │  显示    │
│  线程    │    │  线程    │    │  线程    │    │  线程    │
└──────────┘    └──────────┘    └──────────┘    └──────────┘
      ↓              ↓              ↓              ↓
   [队列1]       [队列2]       [队列3]       [帧缓冲]
```

- **流水线设计**：各环节并行执行
- **队列解耦**：前一环节不等后一环节
- **异步处理**：采集不阻塞

### 3.2 零拷贝设计

```cpp
// 方案一：使用内存池
class FramePool {
    std::vector<std::unique_ptr<uint8_t[]>> pool_;
    std::queue<uint8_t*> available_;
    std::mutex mutex_;
    
public:
    FramePool(size_t frameSize, size_t poolSize) {
        for (size_t i = 0; i < poolSize; i++) {
            pool_.push_back(std::make_unique<uint8_t[]>(frameSize));
            available_.push(pool_.back().get());
        }
    }
    
    uint8_t* acquire() {
        std::lock_guard<std::mutex> lock(mutex_);
        if (available_.empty()) return nullptr;
        uint8_t* ptr = available_.front();
        available_.pop();
        return ptr;
    }
    
    void release(uint8_t* ptr) {
        std::lock_guard<std::mutex> lock(mutex_);
        available_.push(ptr);
    }
};

// 方案二：SDK直接写入共享内存
void onFrameReceived(uint8_t* sdkBuffer, size_t len) {
    // SDK的buffer直接用，不拷贝
    auto frame = std::make_shared<Frame>();
    frame->data = sdkBuffer;  // 直接指向SDK buffer
    frame->releaseFunc = [sdkBuffer]() {
        SDK_ReleaseBuffer(sdkBuffer);  // 用完还给SDK
    };
    
    frameQueue_.push(frame);
}
```

### 3.3 并行处理

```cpp
// 处理线程池
class ProcessingPool {
    std::vector<std::thread> workers_;
    SPSCQueue<FramePtr, 64> inputQueue_;
    SPSCQueue<FramePtr, 64> outputQueue_;
    
public:
    ProcessingPool(int numWorkers) {
        for (int i = 0; i < numWorkers; i++) {
            workers_.emplace_back([this]() {
                while (running_) {
                    FramePtr frame;
                    if (inputQueue_.pop(frame)) {
                        processFrame(frame);  // 耗时操作
                        outputQueue_.push(frame);
                    }
                }
            });
        }
    }
    
private:
    void processFrame(FramePtr& frame) {
        // 图像处理、算法计算等
    }
};
```

### 3.4 控频显示

```cpp
class DisplayManager {
    QTimer refreshTimer_;
    FramePtr latestFrame_;
    std::atomic<bool> frameUpdated_{false};
    
public:
    DisplayManager() {
        refreshTimer_.setInterval(33);  // 30Hz
        connect(&refreshTimer_, &QTimer::timeout, this, &DisplayManager::refresh);
        refreshTimer_.start();
    }
    
    // 从处理线程调用
    void setLatestFrame(const FramePtr& frame) {
        latestFrame_ = frame;
        frameUpdated_.store(true);
    }
    
private slots:
    void refresh() {
        if (frameUpdated_.exchange(false)) {
            // 只在有新帧时才刷新
            displayWidget_->setFrame(latestFrame_);
            displayWidget_->update();
        }
    }
};
```

---

## 四、关键优化点

### 4.1 避免内存分配

```cpp
// 坏：每帧都分配内存
void processFrame(const uint8_t* data, size_t len) {
    std::vector<uint8_t> buffer(len);  // 每帧600KB分配
    memcpy(buffer.data(), data, len);
    // ...
}

// 好：预分配，复用
class FrameProcessor {
    std::vector<uint8_t> buffer_;  // 只分配一次
    
public:
    FrameProcessor() : buffer_(MAX_FRAME_SIZE) {}
    
    void processFrame(const uint8_t* data, size_t len) {
        memcpy(buffer_.data(), data, len);  // 复用buffer
        // ...
    }
};
```

### 4.2 SIMD加速

```cpp
// 普通实现：逐像素转换
void convertToRgb_naive(const uint16_t* raw, uint8_t* rgb, size_t count) {
    for (size_t i = 0; i < count; i++) {
        uint16_t value = raw[i];
        rgb[i * 3 + 0] = colorTable[value].r;
        rgb[i * 3 + 1] = colorTable[value].g;
        rgb[i * 3 + 2] = colorTable[value].b;
    }
}

// SIMD实现：8像素并行
void convertToRgb_simd(const uint16_t* raw, uint8_t* rgb, size_t count) {
    for (size_t i = 0; i < count; i += 8) {
        __m128i values = _mm_loadu_si128((__m128i*)&raw[i]);
        // 用查表+SIMD并行处理8个像素
        // ...
    }
}
```

性能对比：
| 实现 | 640×480帧耗时 |
|------|---------------|
| 普通实现 | 3000μs |
| SIMD实现 | 400μs |

### 4.3 GPU加速（可选）

```cpp
// 用OpenGL渲染，GPU做颜色映射
class GpuRenderer {
    GLuint texture_;
    GLuint shader_;
    
public:
    void uploadFrame(const uint16_t* data, int width, int height) {
        // 上传原始数据到GPU
        glBindTexture(GL_TEXTURE_2D, texture_);
        glTexSubImage2D(GL_TEXTURE_2D, 0, 0, 0, width, height,
                        GL_RED, GL_UNSIGNED_SHORT, data);
    }
    
    void render() {
        // GPU执行颜色映射
        glUseProgram(shader_);
        // ...
    }
};
```

### 4.4 降级策略

```cpp
// 系统负载高时自动降级
class AdaptiveProcessor {
    int currentQuality_ = 100;  // 100%质量
    
public:
    void onFrameDropped() {
        // 检测到丢帧，降低质量
        currentQuality_ = std::max(50, currentQuality_ - 10);
        applyQuality(currentQuality_);
    }
    
    void onSystemIdle() {
        // 系统空闲，提高质量
        currentQuality_ = std::min(100, currentQuality_ + 5);
        applyQuality(currentQuality_);
    }
    
private:
    void applyQuality(int quality) {
        if (quality < 70) {
            // 降低分辨率
            resampleFactor_ = 2;  // 降采样
        } else {
            resampleFactor_ = 1;
        }
        
        if (quality < 50) {
            // 降低帧率
            targetFps_ = 15;
        } else {
            targetFps_ = 25;
        }
    }
};
```

---

## 五、性能验证

### 5.1 测试方法

```cpp
class PerformanceTest {
public:
    void runBenchmark() {
        const int NUM_FRAMES = 1000;
        auto start = std::chrono::high_resolution_clock::now();
        
        for (int i = 0; i < NUM_FRAMES; i++) {
            processFrame(testData_);
        }
        
        auto end = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
        
        double fps = NUM_FRAMES * 1000.0 / duration.count();
        double throughput = fps * FRAME_SIZE / (1024 * 1024);  // MB/s
        
        qDebug() << "FPS:" << fps;
        qDebug() << "Throughput:" << throughput << "MB/s";
    }
};
```

### 5.2 测试结果

| 配置 | FPS | 吞吐量 | CPU占用 |
|------|-----|--------|---------|
| 优化前 | 18 | 10.5MB/s | 85% |
| +零拷贝 | 25 | 15MB/s | 70% |
| +并行处理 | 30 | 18MB/s | 80%（多核） |
| +控频显示 | 30 | 18MB/s | 50% |
| +SIMD | 40 | 24MB/s | 40% |

最终效果：
- 稳定处理25Hz × 600KB = 15MB/s的红外数据流
- CPU占用50%左右，还有余量
- 无丢帧、无卡顿

---

## 六、代码示例

### 6.1 完整的数据处理管线

```cpp
class IrDataPipeline {
    // 三个阶段的队列
    SPSCQueue<RawFramePtr, 8> rawQueue_;      // 采集→解析
    SPSCQueue<ParsedFramePtr, 8> parsedQueue_; // 解析→处理
    SPSCQueue<DisplayFramePtr, 4> displayQueue_; // 处理→显示
    
    std::thread parseThread_;
    std::thread processThread_;
    
public:
    void start() {
        parseThread_ = std::thread([this]() { parseLoop(); });
        processThread_ = std::thread([this]() { processLoop(); });
    }
    
    // 采集回调（SDK线程调用）
    void onRawFrame(uint8_t* data, size_t len) {
        auto frame = std::make_shared<RawFrame>();
        frame->data = data;
        frame->len = len;
        frame->timestamp = getCurrentTimestamp();
        
        if (!rawQueue_.push(frame)) {
            stats_.dropCount++;
        }
    }
    
private:
    void parseLoop() {
        while (running_) {
            RawFramePtr raw;
            if (rawQueue_.pop(raw)) {
                auto parsed = parseFrame(raw);
                parsedQueue_.push(parsed);
            }
        }
    }
    
    void processLoop() {
        while (running_) {
            ParsedFramePtr parsed;
            if (parsedQueue_.pop(parsed)) {
                auto display = processFrame(parsed);
                
                // 只保留最新帧
                DisplayFramePtr old;
                while (displayQueue_.pop(old)) {}  // 清空旧帧
                displayQueue_.push(display);
            }
        }
    }
    
    ParsedFramePtr parseFrame(const RawFramePtr& raw) {
        auto parsed = std::make_shared<ParsedFrame>();
        // 解析帧头、校验等
        return parsed;
    }
    
    DisplayFramePtr processFrame(const ParsedFramePtr& parsed) {
        auto display = std::make_shared<DisplayFrame>();
        // 颜色映射、温度计算等
        return display;
    }
};
```

---

## 七、面试追问准备

### Q1: 15MB/s是怎么测量的？

```
测量方法：
1. 记录一段时间内处理的总字节数
2. 除以时间得到平均吞吐量

具体：
- 红外帧：640×480×2B = 614,400B
- 帧率：25fps
- 吞吐量：614,400 × 25 = 15,360,000 B/s ≈ 15MB/s

验证：用性能计数器统计每秒处理的帧数，稳定在25帧。
```

### Q2: 瓶颈在哪？怎么找到的？

```
用排除法：

1. 先测整体延迟：采集到显示200ms
2. 分段加时间戳：
   - 采集：5ms
   - 解析：2ms
   - 处理：50ms  ← 主要瓶颈
   - UI刷新：100ms ← 另一个瓶颈
3. 针对性优化

最后发现：
- 处理瓶颈：颜色映射算法慢 → SIMD优化
- UI瓶颈：刷新太频繁 → 控频刷新
```

### Q3: 内存占用怎么样？

```
分析：
- 每帧600KB
- 流水线有3个队列，每个8帧深度
- 最坏情况：600KB × 8 × 3 = 14.4MB

实际：
- 用内存池，预分配20帧的buffer
- 总内存：600KB × 20 = 12MB
- 运行时不再分配，无内存碎片

对于嵌入式设备（通常1-2GB内存），12MB完全可接受。
```

### Q4: 如果数据量再大10倍怎么办？

```
150MB/s就需要更激进的优化：

1. 硬件方案
   - 使用FPGA做前端处理
   - 使用GPU加速
   - 使用DMA直接传输

2. 软件方案
   - 降采样：减少需要处理的数据量
   - 压缩：传输压缩数据，CPU解压
   - 分布式：多机处理

3. 架构调整
   - 采集和处理分离到不同设备
   - 用高速接口（PCIe、万兆网）

我们当前设备是ARM平台，15MB/s是合理的上限。
```

### Q5: 延迟和吞吐量怎么平衡？

```
这是个trade-off：

- 增加队列深度 → 吞吐量↑，延迟↑
- 减少队列深度 → 延迟↓，可能丢帧

我们的选择：
- 采集队列：8帧（优先保证不丢帧）
- 显示队列：2帧（优先保证实时性）

最终效果：
- 端到端延迟：80-100ms
- 丢帧率：<0.1%

对于电力检测场景，100ms延迟可接受，丢帧不可接受。
```
