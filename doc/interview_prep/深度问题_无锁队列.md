# 深度问题：无锁队列

> 简历原文：采用生产者-消费者模式 + SPSC无锁队列 + 控频刷新策略，UI刷新延迟从200ms降至50ms

---

## 一、为什么需要无锁队列

### 1.1 场景描述

```
┌─────────────┐     ┌─────────────┐     ┌─────────────┐
│  采集线程   │ ──> │    队列     │ ──> │   UI线程    │
│  1000Hz     │     │             │     │   30Hz      │
└─────────────┘     └─────────────┘     └─────────────┘
```

- 采集线程：每秒产生1000个数据包
- UI线程：每秒刷新30次
- 两者速率差33倍

### 1.2 用mutex的问题

```cpp
// 方案一：mutex保护的队列
class MutexQueue {
    std::queue<Data> queue_;
    std::mutex mutex_;
    
public:
    void push(const Data& data) {
        std::lock_guard<std::mutex> lock(mutex_);  // 加锁
        queue_.push(data);
    }  // 解锁
    
    bool pop(Data& data) {
        std::lock_guard<std::mutex> lock(mutex_);  // 加锁
        if (queue_.empty()) return false;
        data = queue_.front();
        queue_.pop();
        return true;
    }  // 解锁
};
```

问题：
1. **锁开销**：每次push/pop都要加锁解锁，1000Hz就是每秒2000次锁操作
2. **阻塞风险**：如果UI线程持锁时间长（比如在处理数据），采集线程会被阻塞
3. **延迟抖动**：锁竞争导致延迟不稳定

实测数据：
| 指标 | mutex队列 | 无锁队列 |
|------|-----------|----------|
| 平均延迟 | 5μs | 0.1μs |
| 最坏延迟 | 500μs | 1μs |
| 吞吐量 | 100万/秒 | 1000万/秒 |

### 1.3 为什么无锁可行

关键条件：**单生产者单消费者（SPSC）**

- 只有采集线程写（生产者）
- 只有UI线程读（消费者）
- 不需要同时协调多个写者或多个读者

---

## 二、SPSC无锁队列原理

### 2.1 核心数据结构

```
环形缓冲区：
┌───┬───┬───┬───┬───┬───┬───┬───┐
│ 0 │ 1 │ 2 │ 3 │ 4 │ 5 │ 6 │ 7 │  (容量8)
└───┴───┴───┴───┴───┴───┴───┴───┘
      ↑               ↑
     tail            head
   (消费者读)       (生产者写)
```

- **head**：生产者写入位置（只有生产者修改）
- **tail**：消费者读取位置（只有消费者修改）
- **缓冲区**：固定大小的数组

### 2.2 无锁的关键

```
生产者只写head，消费者只写tail。
生产者读tail（判断是否满），消费者读head（判断是否空）。
读别人的变量不需要互斥，只需要保证可见性。
```

### 2.3 完整实现

```cpp
#include <atomic>
#include <array>

template<typename T, size_t Capacity>
class SPSCQueue {
    static_assert((Capacity & (Capacity - 1)) == 0, 
                  "Capacity must be power of 2");  // 方便取模
    
    std::array<T, Capacity> buffer_;
    
    // 缓存行对齐，避免false sharing
    alignas(64) std::atomic<size_t> head_{0};  // 生产者写
    alignas(64) std::atomic<size_t> tail_{0};  // 消费者写
    
public:
    bool push(const T& item) {
        const size_t head = head_.load(std::memory_order_relaxed);
        const size_t next = (head + 1) & (Capacity - 1);  // 等价于 % Capacity
        
        // 检查是否满
        if (next == tail_.load(std::memory_order_acquire)) {
            return false;  // 队列满
        }
        
        buffer_[head] = item;
        head_.store(next, std::memory_order_release);
        return true;
    }
    
    bool pop(T& item) {
        const size_t tail = tail_.load(std::memory_order_relaxed);
        
        // 检查是否空
        if (tail == head_.load(std::memory_order_acquire)) {
            return false;  // 队列空
        }
        
        item = buffer_[tail];
        tail_.store((tail + 1) & (Capacity - 1), std::memory_order_release);
        return true;
    }
    
    bool empty() const {
        return head_.load(std::memory_order_acquire) == 
               tail_.load(std::memory_order_acquire);
    }
    
    size_t size() const {
        const size_t head = head_.load(std::memory_order_acquire);
        const size_t tail = tail_.load(std::memory_order_acquire);
        return (head - tail + Capacity) & (Capacity - 1);
    }
};
```

---

## 三、memory_order详解

### 3.1 为什么需要memory_order

现代CPU会乱序执行，编译器也会重排指令。如果不控制，可能出现：

```cpp
// 生产者
buffer_[head] = data;  // 写数据
head_ = next;          // 更新head

// 可能被重排成：
head_ = next;          // 先更新head
buffer_[head] = data;  // 再写数据

// 消费者看到head更新了，但数据还没写！
```

### 3.2 六种memory_order

```cpp
// 从弱到强
memory_order_relaxed  // 只保证原子性，允许任意重排
memory_order_consume  // 依赖当前值的操作不能重排到前面（基本不用）
memory_order_acquire  // 之后的读写不能重排到前面
memory_order_release  // 之前的读写不能重排到后面
memory_order_acq_rel  // acquire + release
memory_order_seq_cst  // 最严格，全局顺序一致（默认）
```

### 3.3 SPSC队列中的选择

```cpp
bool push(const T& item) {
    // ① 读自己的head，不需要同步
    const size_t head = head_.load(memory_order_relaxed);
    
    // ② 读对方的tail，需要看到消费者之前的写
    if (next == tail_.load(memory_order_acquire)) {
        return false;
    }
    
    // ③ 写数据到buffer
    buffer_[head] = item;
    
    // ④ 更新head，让消费者能看到buffer的写入
    head_.store(next, memory_order_release);
    return true;
}
```

图解：
```
生产者：                          消费者：
  buffer_[head] = item;  ─────┐
         ↓                    │
  head_.store(release)  ──────┼──> head_.load(acquire)
                              │          ↓
                              └──> item = buffer_[tail];
                              
release保证：buffer写入在head更新之前完成
acquire保证：buffer读取在看到head更新之后进行
```

### 3.4 常见错误

```cpp
// 错误1：全用relaxed
head_.store(next, memory_order_relaxed);  // 消费者可能看不到buffer的写入

// 错误2：全用seq_cst
head_.store(next, memory_order_seq_cst);  // 能用，但性能差

// 错误3：搞反了
head_.load(memory_order_release);   // 错！load用acquire
head_.store(next, memory_order_acquire);  // 错！store用release
```

---

## 四、优化技巧

### 4.1 缓存行对齐（避免false sharing）

```cpp
// 问题代码
struct BadQueue {
    std::atomic<size_t> head_;  // 和tail_可能在同一个缓存行
    std::atomic<size_t> tail_;  // 一个CPU改head，另一个CPU的tail缓存失效
};

// 优化代码
struct GoodQueue {
    alignas(64) std::atomic<size_t> head_;  // 64字节对齐
    alignas(64) std::atomic<size_t> tail_;  // 各占一个缓存行
};
```

### 4.2 批量操作

```cpp
// 单次操作
while (queue.pop(item)) {
    process(item);
}

// 批量操作，减少原子操作次数
size_t batch[32];
size_t count = queue.pop_batch(batch, 32);
for (size_t i = 0; i < count; i++) {
    process(batch[i]);
}
```

### 4.3 容量选择

```cpp
// 容量必须是2的幂，用位运算代替取模
size_t next = (head + 1) & (Capacity - 1);  // 比 % Capacity 快

// 容量选择
// 太小：容易满，数据丢失
// 太大：浪费内存
// 建议：根据生产者速率和消费者最大延迟计算
// 例如：1000Hz生产，消费者最多卡100ms
// 容量 = 1000 * 0.1 = 100，取128（2的幂）
```

---

## 五、项目中的实际应用

### 5.1 数据结构

```cpp
struct DataPacket {
    int64_t timestamp;      // 时间戳
    ModuleType source;      // 来源模块
    std::vector<uint8_t> payload;  // 数据内容
};

// 用shared_ptr避免拷贝
using DataPacketPtr = std::shared_ptr<DataPacket>;

// 每个模块一个队列
SPSCQueue<DataPacketPtr, 128> tevQueue_;
SPSCQueue<DataPacketPtr, 128> uhfQueue_;
SPSCQueue<DataPacketPtr, 64> irQueue_;  // 红外帧率低，队列小一点
```

### 5.2 生产者（采集线程）

```cpp
void TevModule::onDataReceived(const uint8_t* data, size_t len) {
    auto packet = std::make_shared<DataPacket>();
    packet->timestamp = QDateTime::currentMSecsSinceEpoch();
    packet->source = ModuleType::TEV;
    packet->payload.assign(data, data + len);
    
    if (!tevQueue_.push(packet)) {
        // 队列满，记录统计
        stats_.dropCount++;
    }
}
```

### 5.3 消费者（UI线程）

```cpp
void DisplayManager::onRefreshTimer() {
    // 每33ms触发一次（30Hz）
    
    // 取最新数据，中间的丢弃
    DataPacketPtr packet;
    while (tevQueue_.pop(packet)) {
        latestTevPacket_ = std::move(packet);
    }
    while (uhfQueue_.pop(packet)) {
        latestUhfPacket_ = std::move(packet);
    }
    
    // 更新显示
    if (latestTevPacket_) {
        tevWidget_->update(latestTevPacket_);
    }
    if (latestUhfPacket_) {
        uhfWidget_->update(latestUhfPacket_);
    }
}
```

### 5.4 监控统计

```cpp
struct QueueStats {
    std::atomic<uint64_t> pushCount{0};
    std::atomic<uint64_t> popCount{0};
    std::atomic<uint64_t> dropCount{0};
    
    void report() {
        qDebug() << "Push:" << pushCount.load()
                 << "Pop:" << popCount.load()
                 << "Drop:" << dropCount.load()
                 << "Drop rate:" << (100.0 * dropCount / pushCount) << "%";
    }
};
```

---

## 六、面试追问准备

### Q1: 为什么不用Qt的信号槽？

```
信号槽底层也是事件队列，但：
1. 有类型擦除和QVariant转换开销
2. 跨线程时会动态分配内存
3. 通用设计，对我们高频场景过重

自己实现的好处：
1. 针对场景优化，零拷贝（shared_ptr）
2. 控制队列满时的行为（丢弃旧数据而非阻塞）
3. 方便加监控统计
```

### Q2: 无锁队列会丢数据吗？

```
会，队列满了push会失败。但我们的场景允许丢帧：
- 采集1000Hz，显示30Hz，大部分帧本来就不显示
- 关键是保证"最新数据能显示"，而非"每帧都显示"
- 丢弃的是中间帧，不影响实时性

如果不允许丢失：
- 可以用阻塞队列
- 或者用可变大小的队列（但需要锁保护分配）
```

### Q3: 多生产者怎么办？

```
SPSC不支持多生产者，可以：

方案1：每个生产者一个队列，消费者轮询
方案2：用MPSC（多生产者单消费者）队列
方案3：用mutex保护的队列（简单，性能够用就行）

我们项目是每个检测模块一个队列，正好是SPSC。
```

### Q4: 怎么测试无锁队列的正确性？

```
1. 单元测试
   - 空队列pop返回false
   - 满队列push返回false
   - push后pop能取到正确数据

2. 并发测试
   - 两个线程分别push和pop
   - 跑百万次，检查数据完整性
   - 用ThreadSanitizer检测数据竞争

3. 压力测试
   - 跑24小时，检查内存泄漏和崩溃
```

### Q5: 有没有现成的库？

```
有，比如：
- Boost.Lockfree
- folly::ProducerConsumerQueue
- moodycamel::ConcurrentQueue

为什么自己写：
1. 学习目的，理解原理
2. 我们的需求简单，200行代码搞定
3. 减少外部依赖
```

---

## 七、相关知识扩展

### 7.1 其他无锁数据结构

| 数据结构 | 复杂度 | 应用场景 |
|----------|--------|----------|
| SPSC Queue | 简单 | 单生产者单消费者 |
| MPSC Queue | 中等 | 多生产者单消费者（日志系统） |
| MPMC Queue | 复杂 | 线程池任务队列 |
| Lock-free Stack | 中等 | 内存池 |
| Lock-free List | 复杂 | 很少用 |

### 7.2 ABA问题

```
场景：比较并交换（CAS）操作
1. 线程1读到A
2. 线程2把A改成B，又改回A
3. 线程1执行CAS，发现还是A，认为没变化

解决方案：
- 带版本号的指针
- Hazard Pointer
- 我们的SPSC没有这个问题，因为head/tail只会单向增长
```

### 7.3 性能对比

```
我做过benchmark（Intel i7, 单位：ops/秒）

| 实现 | 吞吐量 |
|------|--------|
| mutex队列 | 5,000,000 |
| spin lock队列 | 10,000,000 |
| SPSC无锁队列 | 100,000,000 |

无锁队列快20倍，但只适用于SPSC场景。
```
