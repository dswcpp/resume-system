[
  {
    "id": "cpp_001",
    "question": "详细解释C++中的虚函数机制及其实现原理",
    "tags": ["C++基础", "多态", "虚函数", "vtable", "内存布局"],
    "difficulty": 1,
    "hint": "从vtable/vptr机制入手，讲清编译器做了什么、运行时如何查表调用，再提内存开销和性能影响。",
    "answer": "C++虚函数是实现多态的关键机制：\n\n1. **工作原理**：\n   - 当类声明虚函数时，编译器为该类创建虚函数表(vtable)\n   - 每个包含虚函数的类对象都有一个虚函数指针(vptr)，指向该类的vtable\n   - 调用虚函数时，程序通过vptr查找vtable，找到对应函数地址并调用\n\n2. **内存布局**：\n   - 对象内存布局通常是vptr在最前面，后跟类成员变量\n   - 每个类只有一个vtable，所有该类对象共享\n   - 派生类的vtable包含继承的虚函数，可能被重写的函数指向派生类实现\n\n3. **性能影响**：\n   - 每个对象增加一个指针大小(通常8字节)的内存开销\n   - 虚函数调用比普通函数调用慢(通常需要额外的内存访问)\n   - 可能阻碍某些编译器优化(如内联)\n\n在实际工作中，我为一个图像处理库优化了类层次结构，将非必要的虚函数改为非虚函数，对频繁调用的小型虚函数进行了特殊优化，最终提升了处理性能约15%。我们保留了关键接口的多态性，同时减少了虚函数调用开销。",
    "source": "C++面试准备.md"
  },
  {
    "id": "cpp_002",
    "question": "shared_ptr的实现原理是什么？使用时应注意哪些问题？",
    "tags": ["C++11", "智能指针", "shared_ptr", "引用计数", "内存管理"],
    "difficulty": 2,
    "hint": "讲清控制块结构（引用计数+弱引用计数+删除器），再展开循环引用、线程安全、make_shared优势等注意事项。",
    "answer": "shared_ptr是C++11引入的智能指针，实现了引用计数的共享所有权：\n\n1. **实现原理**：\n   - 包含两个指针：一个指向管理的对象，一个指向控制块\n   - 控制块包含引用计数、弱引用计数和删除器\n   - 拷贝shared_ptr时增加引用计数，销毁时减少计数\n   - 当引用计数归零时，删除管理的对象和控制块\n\n2. **注意事项**：\n   - **循环引用问题**：相互引用的shared_ptr会导致内存泄漏，应使用weak_ptr打破循环\n   - **线程安全性**：引用计数操作是原子的，但对象访问不是线程安全的\n   - **自定义删除器**：可能增加控制块大小，影响性能\n   - **make_shared优势**：一次分配控制块和对象，减少内存分配次数\n\n3. **最佳实践**：\n   - 优先使用make_shared而非直接构造\n   - 避免从裸指针构造多个shared_ptr\n   - 合理使用weak_ptr监视对象生命周期\n   - 谨慎管理this指针的共享所有权(避免直接构造shared_ptr<this>)\n\n在我开发的一个插件系统中，最初使用裸指针管理组件导致内存泄漏和悬空指针问题。重构为shared_ptr/weak_ptr架构后，通过weak_ptr安全地访问可能已被销毁的组件，解决了崩溃问题，同时优化了使用make_shared的内存分配，降低了30%的内存碎片。",
    "source": "C++面试准备.md"
  },
  {
    "id": "cpp_003",
    "question": "解释C++中的完美转发(Perfect Forwarding)及其实现原理",
    "tags": ["C++11", "完美转发", "右值引用", "std::forward", "模板", "移动语义"],
    "difficulty": 2,
    "hint": "核心是万能引用T&&加std::forward，讲清引用折叠规则（左值→T&，右值→T&&），再举emplace或工厂函数的例子。",
    "answer": "完美转发是C++11引入的机制，用于在泛型代码中保持参数的值类别(左值/右值)和CV限定符(const/volatile)：\n\n1. **核心机制**：\n   - 结合万能引用(T&&)和std::forward实现\n   - 万能引用根据传入实参自动推导为左值或右值引用\n   - std::forward根据模板参数类型进行条件式转换\n\n2. **工作原理**：\n   - 当传入左值时，T被推导为左值引用类型，T&& 折叠为左值引用(T&)\n   - 当传入右值时，T被推导为非引用类型，T&& 保持为右值引用\n   - std::forward根据T是否为引用类型决定返回左值或右值\n\n3. **应用场景**：\n   - 工厂函数和构造函数包装器\n   - 容器的emplace系列函数\n   - 任何需要透明传递参数的中间层函数\n\n```cpp\ntemplate<typename T, typename... Args>\nunique_ptr<T> make_unique(Args&&... args) {\n    return unique_ptr<T>(new T(std::forward<Args>(args)...));\n}\n```\n\n在开发一个高性能信号槽系统时，我实现了参数完美转发机制，允许信号传递任意类型参数到槽函数，避免了不必要的对象拷贝。对于大型对象，这种优化减少了50%以上的开销，同时支持了移动语义，显著提升了系统性能。",
    "source": "C++面试准备.md"
  },
  {
    "id": "cpp_004",
    "question": "解释内存模型和原子操作在多线程编程中的重要性",
    "tags": ["C++11", "多线程", "内存模型", "原子操作", "memory_order", "无锁编程"],
    "difficulty": 3,
    "hint": "先讲内存序的概念（为什么CPU/编译器会重排），再分层讲relaxed→acquire/release→seq_cst，最后举无锁数据结构的实战例子。",
    "answer": "C++11引入的内存模型和原子操作是正确编写多线程代码的基础：\n\n1. **内存模型核心概念**：\n   - **内存序(Memory Ordering)**：定义多线程程序中内存访问的可见性和顺序\n   - **同步关系(Synchronizes-With)**：建立线程间的因果关系\n   - **数据竞争(Data Race)**：并发访问同一内存位置且至少有一个是写操作\n\n2. **原子操作类型**：\n   - **memory_order_relaxed**：最弱保证，只保证原子性，不提供同步\n   - **memory_order_acquire/release**：建立同步关系，保证可见性\n   - **memory_order_acq_rel**：结合获取和释放语义\n   - **memory_order_seq_cst**：最强保证，全序关系，是默认选项\n\n3. **实际应用**：\n   - 无锁数据结构实现\n   - 自定义同步原语\n   - 高性能并发算法\n   - 硬件交互和驱动开发\n\n在我负责的一个实时数据处理系统中，通过使用正确的内存序优化无锁队列实现，比mutex版本提高了3倍吞吐量。为解决特定CPU架构上的内存重排序问题，精确使用memory_order_acquire/release确保生产者-消费者模式的正确性，同时避免了全序(seq_cst)带来的性能开销。",
    "source": "C++面试准备.md"
  },
  {
    "id": "cpp_005",
    "question": "如何处理C++项目中的异常安全性问题？",
    "tags": ["C++", "异常安全", "RAII", "智能指针", "资源管理", "设计模式"],
    "difficulty": 2,
    "hint": "先说三个保证级别（基本/强/noexcept），再讲RAII、智能指针、复制-交换等实现手段，最后举事务型操作的项目例子。",
    "answer": "异常安全性是健壮C++程序的关键特性，关注资源管理和状态一致性：\n\n1. **异常安全性保证级别**：\n   - **基本保证**：异常发生时不泄露资源，对象仍可用但状态可能改变\n   - **强保证**：异常发生时操作要么完全成功，要么状态不变(类似事务)\n   - **不抛异常保证**：操作保证不会抛出异常(noexcept函数)\n\n2. **实现技术**：\n   - **RAII模式**：资源获取即初始化，自动管理资源生命周期\n   - **智能指针**：自动管理动态分配的内存\n   - **复制-交换习惯用法**：实现强异常安全保证\n   - **异常中立代码**：不捕获不处理的异常应当传播\n\n3. **最佳实践**：\n   - 构造函数应提供强异常安全保证\n   - 析构函数不应抛出异常(通常标记为noexcept)\n   - 使用标准库容器和算法获得内置的异常安全性\n   - 大型状态变更使用\"提交-回滚\"模式\n\n在一个金融数据处理系统中，我重构了交易处理模块以确保异常安全。通过RAII封装数据库事务，实现了完整的回滚机制；使用std::optional存储中间结果避免部分修改状态；将函数重构为\"准备-提交\"两阶段模式，即使在网络故障时也能保持数据一致性。这些改进消除了之前系统偶发的数据不一致问题。",
    "source": "C++面试准备.md"
  },
  {
    "id": "cpp_006",
    "question": "你平时STL用得多吗？常用哪些容器？怎么选？",
    "tags": ["STL", "容器选择", "vector", "map", "unordered_map", "设计原则"],
    "difficulty": 1,
    "hint": "开场先给原则：能用vector就vector，关联容器看是否需要有序，再按场景展开各容器选型理由。",
    "answer": "平时 STL 用得比较多，整体原则是：能用 `std::vector` 就用 `std::vector`，关联容器用 `std::map` / `std::unordered_map`，只有在需要稳定迭代器且频繁中间插入的特殊场景才考虑 `std::list`。\n\n- `std::vector` 底层是动态数组，内存连续，适合大量遍历和算法运算，随机访问 O(1)、尾部插入高效；缺点是中间插入/删除要移动元素。\n- `std::list` 是双向链表，插入/删除当前节点 O(1)，但因为节点分散、cache 友好度差、定位也要遍历，所以并不常用。\n- 在 Qt 里，`QVector` 类似 `std::vector`，处理波形数据、FFT 等场景都用 `QVector<float>`；`QList` 在 Qt5 的很多场景性能不如 `QVector`，新代码倾向于用 `QVector`。\n- 关联容器方面，`std::map` / `QMap` 有序、O(log n)，适合有序遍历/范围查询；`std::unordered_map` 是哈希表，平均 O(1) 查找，适合字典型映射，如设备 ID 到处理对象。\n\n实际项目里，在带电检测终端一帧采样数据用 `QVector<float>` 存储便于算法运算；在柜外交互终端中管理多个设备/会话用 `std::unordered_map<std::string, Session>` 做映射。另会注意不同容器的迭代器失效规则，例如在 `std::vector` 中扩容或中间插入后旧迭代器会失效，遍历删元素时用 `erase(it++)` 或先记录 key 再统一删除，避免问题。",
    "source": "STL面试回答模板.md"
  },
  {
    "id": "cpp_007",
    "question": "vector和list有什么区别？什么时候用list？",
    "tags": ["STL", "vector", "list", "数据结构", "缓存友好", "性能"],
    "difficulty": 1,
    "hint": "从底层实现（连续数组vs双向链表）讲起，重点强调cache友好性使vector在多数场景胜出，list只在需要稳定迭代器+频繁中间插删时才考虑。",
    "answer": "从底层实现看：\n- `std::vector` 是动态数组，内存连续，随机访问是 O(1)，在尾部 `push_back` 很高效；在中间插入/删除需要移动后面的元素，时间复杂度是 O(n)。\n- `std::list` 是双向链表，每个节点分散在堆上，插入和删除某个位置本身是 O(1)，但是为了找到这个位置通常要遍历，整体还是 O(n)，而且因为链表不连续，对 CPU cache 不友好。\n\n所以大部分情况下优先选 `std::vector`，原因是：\n1. 内存连续，对 cache 友好，遍历性能很好。\n2. 很多算法可以用 `memcpy` / SIMD 等手段优化。\n3. 即使在中间插入/删除，只要数据量不是特别夸张，整体性能通常也比 list 好。\n\n只有在必须频繁在中间插入/删除，而且又需要稳定迭代器/引用时，才会考虑用 `std::list`，但这种场景在实际项目里其实并不多。\n\n**Qt补充**：\n- `QVector` 本质上和 `std::vector` 类似，也是连续内存，非常适合和 C 接口、底层 buffer 打交道。\n- `QList` 在 Qt5 里底层是\"数组 + 间接指针\"，在小对象场景下会多一次指针跳转，不一定比 `QVector` 快；Qt6 之后 `QList` 已经基本等同于 `QVector`。\n\n**项目举例**：在带电检测终端里，一帧波形数据用 `std::vector<float>` 或 `QVector<float>` 存，因为需要频繁做 FFT、滤波运算，连续内存可以直接传给底层算法库；遍历访问非常多，而中间插入几乎没有。曾经使用 `QList<float>`，在大量数据点情况下性能明显差一些，统一换成 `QVector` 后，整条处理链路的 CPU 占用有明显下降。",
    "source": "STL面试回答模板.md"
  },
  {
    "id": "cpp_008",
    "question": "map和unordered_map有什么区别？怎么选？",
    "tags": ["STL", "map", "unordered_map", "红黑树", "哈希表", "关联容器"],
    "difficulty": 1,
    "hint": "map是红黑树有序O(log n)，unordered_map是哈希表无序O(1)均摊；需要有序遍历/范围查询选map，纯查找选unordered_map并注意reserve。",
    "answer": "- `std::map` 底层一般是红黑树，是有序关联容器，key 有序；查找、插入、删除都是 O(log n)，支持有序遍历、`lower_bound`。\n- `std::unordered_map` 底层是哈希表，是无序容器；平均查找、插入、删除是 O(1)，最坏 O(n)；不能有序遍历，但大数据量下查找通常更好。\n\n选择习惯：\n- 需要有序遍历 / 范围查询（如按 key 顺序导出配置）用 `std::map` / `QMap`。\n- 只是频繁查找、不关心顺序，用 `std::unordered_map` 做字典，并注意 `reserve` 预留 bucket，减少 rehash。\n\n**QMap 补充**：`QMap` 底层也是平衡树，语义更接近 `std::map`；和 Qt 的信号槽、序列化、`QVariant` 配合更顺畅，涉及 Qt 生态时可优先用 `QMap`。\n\n**项目例子**：在柜外交互终端里，用 `std::unordered_map<std::string, DeviceHandler>` 管理设备 ID 到处理对象的映射，因为设备 ID 查找非常频繁，但不关心遍历顺序；哈希表查找接近 O(1)，比 `std::map` 更合适。而在配置管理场景，比如按 key 排序展示，使用 `std::map` 或 `QMap`，直接利用其有序性遍历输出。",
    "source": "STL面试回答模板.md"
  },
  {
    "id": "cpp_009",
    "question": "STL容器的迭代器失效规则是什么？实际开发中如何避免踩坑？",
    "tags": ["STL", "迭代器失效", "vector", "list", "map", "最佳实践"],
    "difficulty": 2,
    "hint": "按容器分类讲失效规则（vector扩容全失效、list只失效被删节点、map/unordered_map各有不同），再给实践技巧：erase(it++)或先记key后删。",
    "answer": "在实际使用 STL 容器时，需要注意迭代器失效问题：\n- `std::vector` 扩容时，之前所有迭代器、指针、引用都会失效；中间插入/删除也会让后面元素的迭代器失效。\n- `std::list` 在插入、删除其他元素时，已有元素的迭代器稳定，这是其优势之一。\n- `std::map` / `std::unordered_map` 在插入/删除时有各自的迭代器/引用失效规则，需查文档或谨慎使用。\n\n实践习惯：容器操作（特别是插入/删除）后，尽量不要复用之前保存的迭代器/引用，而是用新的 `begin()` / `find()` 重新获取，或把生命周期控制在小范围内，避免踩坑。\n\n可用技巧：\n- 不在遍历过程中直接删除当前元素，而用 `erase(it++)` 模式；\n- 或先记录 key，遍历结束后统一删除。",
    "source": "STL面试回答模板.md"
  },
  {
    "id": "cpp_010",
    "question": "你对现代C++(C++11/14/17)的理解是什么？在项目中用过哪些特性？",
    "tags": ["C++11", "C++14", "C++17", "现代C++", "全局观"],
    "difficulty": 1,
    "hint": "按标准版本分层回答：C++11打地基（智能指针/移动语义/lambda/线程库）、C++14补丁（泛型lambda/make_unique）、C++17工具库（optional/variant/string_view/结构化绑定）。",
    "answer": "我这几年的项目基本都是用现代 C++ 做的，对 C++11/14/17 的核心特性用得比较多。我的理解是：\n\n- **C++11** 主要是把\"现代 C++ 的地基打好\"，比如智能指针、右值引用/移动语义、lambda、`auto`、`std::thread` 等，这些用得最多；\n- **C++14** 在语法和库上做了一些增强，比如泛型 lambda、`std::make_unique` 等，更多是让代码更简洁；\n- **C++17** 则在工具型库上补了很多坑，比如 `std::optional`、`std::variant`、`std::string_view`、结构化绑定等，这些在写业务代码和接口设计时帮助很大。\n\n多线程方面，主要是结合 `std::thread` / `std::mutex` / `std::condition_variable` 和 Qt 的 `QThread`，在项目里实现了生产者-消费者的数据通道和多线程数据处理流水线，重点是用合适的同步原语保证线程安全，同时尽量减少锁粒度。",
    "source": "现代C++与多线程面试回答模板.md"
  },
  {
    "id": "cpp_011",
    "question": "C++11的智能指针你是怎么用的？在项目中有什么实际案例？",
    "tags": ["C++11", "智能指针", "unique_ptr", "shared_ptr", "weak_ptr", "RAII"],
    "difficulty": 1,
    "hint": "按所有权语义分：unique_ptr唯一所有权（设备句柄）、shared_ptr共享所有权（共享数据源）、weak_ptr打破循环引用，再举裸指针重构的项目案例。",
    "answer": "在 C++11 里用得最多的就是智能指针：\n\n- `std::unique_ptr` 表示唯一所有权，用在某个对象只被一个模块管理的场景，比如设备连接对象、会话对象；\n- `std::shared_ptr` 表示共享所有权，多个地方共同持有，比如订阅同一个数据源时；\n- `std::weak_ptr` 用来打破 `shared_ptr` 的循环引用。\n\n**项目案例**：在带电检测终端项目里，之前有部分代码用裸指针管理设备句柄，容易出现生命周期问题。重构之后用 `unique_ptr` 管理底层资源，对外只暴露原始句柄或引用，这样在异常情况下也能确保资源被正确释放，现场崩溃率明显降低。\n\n**最佳实践**：新代码基本不再直接用 `new/delete`，统一用 `std::make_unique` / `std::make_shared`，既安全又简洁。",
    "source": "现代C++与多线程面试回答模板.md"
  },
  {
    "id": "cpp_012",
    "question": "右值引用和移动语义是什么？你在项目中怎么用的？",
    "tags": ["C++11", "右值引用", "移动语义", "std::move", "完美转发", "性能优化"],
    "difficulty": 2,
    "hint": "先说目的（减少不必要拷贝），再讲容器push_back临时对象走移动构造、函数返回大对象的RVO，最后举生产者线程移动buffer到消费者队列的例子。",
    "answer": "右值引用和移动语义主要是用来减少不必要的拷贝，提高性能：\n\n- 容器在 `push_back` 一个临时对象时，可以调用移动构造而不是拷贝；\n- 函数返回大对象时，如果支持移动，返回值优化更明显。\n\n**项目应用**：在实时数据处理场景里，用移动语义把一块采集到的波形 buffer 从生产者线程\"移动\"到消费者线程的队列里，而不是再拷贝一份，减少内存带宽压力。\n\n泛型代码里用 `T&&` + `std::forward<T>` 做完美转发，封装工厂函数或 `emplace` 接口时保持参数值类别，避免多余拷贝。",
    "source": "现代C++与多线程面试回答模板.md"
  },
  {
    "id": "cpp_013",
    "question": "lambda、auto、range-for这些C++11语法糖你怎么用？",
    "tags": ["C++11", "lambda", "auto", "range-for", "语法糖", "STL算法"],
    "difficulty": 1,
    "hint": "lambda用在回调/STL算法/Qt信号槽就地写逻辑，auto简化复杂类型声明，range-for让遍历更直观，举一两个项目里的小例子即可。",
    "answer": "- **lambda** 用在回调、STL 算法、Qt 信号槽里，把小的处理逻辑就地写清楚；\n- **auto** 简化复杂类型声明，减少类型改动时的维护成本；\n- **range-for** 让容器遍历更直观。\n\n例如处理一帧数据时，用 `std::for_each` 配合 lambda 做变换；在 Qt 里用 lambda 连接信号槽，避免额外写很多 slot。",
    "source": "现代C++与多线程面试回答模板.md"
  },
  {
    "id": "cpp_014",
    "question": "C++14相比C++11有哪些值得提的改进？",
    "tags": ["C++14", "泛型lambda", "make_unique", "返回类型推导"],
    "difficulty": 1,
    "hint": "C++14是C++11的补丁，重点提泛型lambda（参数用auto）和std::make_unique（补上的工厂函数），简洁即可。",
    "answer": "C++14 更多是对 C++11 的\"补丁\"和增强：\n\n1. **泛型 lambda**：在 lambda 参数里用 `auto` 写模板式匿名函数，通用工具/算法封装很方便；\n2. **`std::make_unique`**：正式补上的工厂函数，统一用它创建 `unique_ptr`，避免手写 `new`。\n\n另有返回类型推导等特性，在模板代码里让类型声明更简洁。",
    "source": "现代C++与多线程面试回答模板.md"
  },
  {
    "id": "cpp_015",
    "question": "C++17你用过哪些特性？optional、variant、string_view分别解决什么问题？",
    "tags": ["C++17", "optional", "variant", "string_view", "结构化绑定", "接口设计"],
    "difficulty": 2,
    "hint": "optional表达\"可能没有值\"替代nullptr/特殊值；variant是类型安全的union替代；string_view是非拥有的只读字符串视图减少拷贝；结构化绑定简化pair/tuple解包。",
    "answer": "### `std::optional`\n表达\"可能没有值\"，比特殊返回值或裸指针更清晰。比如解析配置或查找设备，找不到就返回 `std::nullopt`，调用方必须显式判断，错误处理更完整。\n\n项目示例：`std::optional<DeviceInfo> findDevice(id)` 比返回 `nullptr` 或布尔配输出参数更直观，减少空指针问题。\n\n### `std::variant`\n表达一组类型枚举，结合 `std::visit` 分发逻辑，比 `union + enum` 更安全。适合统一处理不同类型消息体的场景。\n\n### `std::string_view`\n非 owning 的字符串视图，在只读场景减少拷贝。处理网络报文或串口数据时，用 `string_view` 在原始 buffer 上切片，避免构造大量 `std::string`，降低分配与临时对象开销。\n\n### 结构化绑定 / if with init\n解包 `pair/tuple` 或 map 遍历：`for (auto& [key, value] : myMap) {...}`。\n带初始化的 if：`if (auto it = map.find(k); it != map.end())` 限制作用域更小，代码更紧凑。",
    "source": "现代C++与多线程面试回答模板.md"
  },
  {
    "id": "cpp_016",
    "question": "你在多线程编程中用了哪些同步工具？线程安全怎么保证的？",
    "tags": ["多线程", "线程安全", "mutex", "condition_variable", "atomic", "生产者-消费者", "Qt"],
    "difficulty": 2,
    "hint": "先说工具集（标准库mutex/lock_guard/condition_variable/atomic + Qt QThread/信号槽），再给四条关键习惯（明确线程边界、RAII锁、减小锁粒度、原子标志），最后描述生产者-消费者流水线项目。",
    "answer": "**工具与模型**：\n- 标准库：`std::thread`、`std::mutex`、`std::lock_guard` / `std::unique_lock`、`std::condition_variable`、`std::atomic`；\n- Qt：`QThread`、`moveToThread`、跨线程信号槽。\n\n设计上优先生产者-消费者与任务队列，让线程通过队列交互，而非共享同一可变数据，锁更少、线程安全更容易。\n\n**线程安全关键习惯**：\n1. 明确线程边界：设计阶段划清单线程访问与共享数据；\n2. RAII 管理锁：统一用 `std::lock_guard` / `std::unique_lock` 包装 `std::mutex`；\n3. 减少锁粒度：缩小加锁范围，避免持锁做 IO/耗时操作；\n4. 原子类型处理标志/计数：用 `std::atomic<bool/int>`，避免为布尔值加大锁。\n\n**项目实战**：在带电检测终端项目中，采用多线程数据处理流水线：\n- 采集线程从设备/驱动读取原始数据；\n- 一个或多个处理线程做滤波、FFT、特征提取；\n- UI 线程负责展示实时波形和告警信息。\n\n模型：生产者-消费者。采集线程将数据块放入线程安全队列，处理线程取出计算，结果通过信号槽或队列传回 UI。队列实现先用 `std::queue + mutex + condition_variable`，热点路径改为无锁环形缓冲（SPSC 队列）降低锁竞争。\n\n效果：在 15MB/s 数据流量下稳定运行不丢数，CPU 占用与延迟可控，UI 流畅。",
    "source": "现代C++与多线程面试回答模板.md"
  },
  {
    "id": "cpp_017",
    "question": "为什么需要无锁队列？mutex队列有什么问题？",
    "tags": ["无锁编程", "mutex", "SPSC", "性能", "延迟", "生产者-消费者"],
    "difficulty": 2,
    "hint": "从具体场景切入（采集1000Hz vs UI 30Hz），列出mutex的三个问题（锁开销、阻塞风险、延迟抖动），给出实测对比数据，再说明SPSC场景为何无锁可行。",
    "answer": "### 场景描述\n```\n┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n│  采集线程   │ ──> │    队列     │ ──> │   UI线程    │\n│  1000Hz     │     │             │     │   30Hz      │\n└─────────────┘     └─────────────┘     └─────────────┘\n```\n- 采集线程：每秒产生1000个数据包\n- UI线程：每秒刷新30次\n- 两者速率差33倍\n\n### mutex队列的问题\n```cpp\nclass MutexQueue {\n    std::queue<Data> queue_;\n    std::mutex mutex_;\npublic:\n    void push(const Data& data) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        queue_.push(data);\n    }\n    bool pop(Data& data) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        if (queue_.empty()) return false;\n        data = queue_.front();\n        queue_.pop();\n        return true;\n    }\n};\n```\n\n问题：\n1. **锁开销**：每次push/pop都要加锁解锁，1000Hz就是每秒2000次锁操作\n2. **阻塞风险**：如果UI线程持锁时间长，采集线程会被阻塞\n3. **延迟抖动**：锁竞争导致延迟不稳定\n\n### 实测对比\n| 指标 | mutex队列 | 无锁队列 |\n|------|-----------|----------|\n| 平均延迟 | 5μs | 0.1μs |\n| 最坏延迟 | 500μs | 1μs |\n| 吞吐量 | 100万/秒 | 1000万/秒 |\n\n### 为什么无锁可行\n关键条件：**单生产者单消费者（SPSC）**\n- 只有采集线程写（生产者）\n- 只有UI线程读（消费者）\n- 不需要同时协调多个写者或多个读者",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_018",
    "question": "请详细讲解SPSC无锁队列的实现原理和完整代码",
    "tags": ["无锁编程", "SPSC", "环形缓冲区", "atomic", "memory_order", "缓存行对齐"],
    "difficulty": 3,
    "hint": "核心是环形缓冲区+两个原子索引（head生产者写/tail消费者写），关键在于各自只写自己的索引、读对方的索引判满/空，用acquire/release保证可见性。",
    "answer": "### 核心数据结构\n```\n环形缓冲区：\n┌───┬───┬───┬───┬───┬───┬───┬───┐\n│ 0 │ 1 │ 2 │ 3 │ 4 │ 5 │ 6 │ 7 │  (容量8)\n└───┴───┴───┴───┴───┴───┴───┴───┘\n      ↑               ↑\n     tail            head\n   (消费者读)       (生产者写)\n```\n\n- **head**：生产者写入位置（只有生产者修改）\n- **tail**：消费者读取位置（只有消费者修改）\n- **缓冲区**：固定大小的数组\n\n### 无锁的关键\n生产者只写head，消费者只写tail。\n生产者读tail（判断是否满），消费者读head（判断是否空）。\n读别人的变量不需要互斥，只需要保证可见性。\n\n### 完整实现\n```cpp\n#include <atomic>\n#include <array>\n\ntemplate<typename T, size_t Capacity>\nclass SPSCQueue {\n    static_assert((Capacity & (Capacity - 1)) == 0, \n                  \"Capacity must be power of 2\");\n    \n    std::array<T, Capacity> buffer_;\n    \n    // 缓存行对齐，避免false sharing\n    alignas(64) std::atomic<size_t> head_{0};\n    alignas(64) std::atomic<size_t> tail_{0};\n    \npublic:\n    bool push(const T& item) {\n        const size_t head = head_.load(std::memory_order_relaxed);\n        const size_t next = (head + 1) & (Capacity - 1);\n        \n        if (next == tail_.load(std::memory_order_acquire)) {\n            return false;  // 队列满\n        }\n        \n        buffer_[head] = item;\n        head_.store(next, std::memory_order_release);\n        return true;\n    }\n    \n    bool pop(T& item) {\n        const size_t tail = tail_.load(std::memory_order_relaxed);\n        \n        if (tail == head_.load(std::memory_order_acquire)) {\n            return false;  // 队列空\n        }\n        \n        item = buffer_[tail];\n        tail_.store((tail + 1) & (Capacity - 1), std::memory_order_release);\n        return true;\n    }\n    \n    bool empty() const {\n        return head_.load(std::memory_order_acquire) == \n               tail_.load(std::memory_order_acquire);\n    }\n    \n    size_t size() const {\n        const size_t head = head_.load(std::memory_order_acquire);\n        const size_t tail = tail_.load(std::memory_order_acquire);\n        return (head - tail + Capacity) & (Capacity - 1);\n    }\n};\n```",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_019",
    "question": "memory_order是什么？SPSC队列中为什么要用acquire/release而不是全用relaxed或seq_cst？",
    "tags": ["无锁编程", "memory_order", "acquire", "release", "relaxed", "seq_cst", "指令重排"],
    "difficulty": 3,
    "hint": "先说为什么需要（CPU乱序执行+编译器重排可能让消费者看到head更新但数据未写入），再分层讲6种memory_order从弱到强，最后在push/pop中逐行分析选择理由。",
    "answer": "### 为什么需要memory_order\n现代CPU会乱序执行，编译器也会重排指令。如果不控制，可能出现：\n\n```cpp\n// 生产者\nbuffer_[head] = data;  // 写数据\nhead_ = next;          // 更新head\n\n// 可能被重排成：\nhead_ = next;          // 先更新head\nbuffer_[head] = data;  // 再写数据\n\n// 消费者看到head更新了，但数据还没写！\n```\n\n### 六种memory_order（从弱到强）\n```cpp\nmemory_order_relaxed  // 只保证原子性，允许任意重排\nmemory_order_consume  // 依赖当前值的操作不能重排到前面（基本不用）\nmemory_order_acquire  // 之后的读写不能重排到前面\nmemory_order_release  // 之前的读写不能重排到后面\nmemory_order_acq_rel  // acquire + release\nmemory_order_seq_cst  // 最严格，全局顺序一致（默认）\n```\n\n### SPSC队列中的选择\n```cpp\nbool push(const T& item) {\n    // ① 读自己的head，不需要同步 → relaxed\n    const size_t head = head_.load(memory_order_relaxed);\n    \n    // ② 读对方的tail，需要看到消费者之前的写 → acquire\n    if (next == tail_.load(memory_order_acquire)) {\n        return false;\n    }\n    \n    // ③ 写数据到buffer\n    buffer_[head] = item;\n    \n    // ④ 更新head，让消费者能看到buffer的写入 → release\n    head_.store(next, memory_order_release);\n    return true;\n}\n```\n\n### 图解同步关系\n```\n生产者：                          消费者：\n  buffer_[head] = item;  ─────┐\n         ↓                    │\n  head_.store(release)  ──────┼──> head_.load(acquire)\n                              │          ↓\n                              └──> item = buffer_[tail];\n\nrelease保证：buffer写入在head更新之前完成\nacquire保证：buffer读取在看到head更新之后进行\n```\n\n### 常见错误\n```cpp\n// 错误1：全用relaxed → 消费者可能看不到buffer的写入\nhead_.store(next, memory_order_relaxed);\n\n// 错误2：全用seq_cst → 能用，但性能差\nhead_.store(next, memory_order_seq_cst);\n\n// 错误3：搞反了\nhead_.load(memory_order_release);   // 错！load用acquire\nhead_.store(next, memory_order_acquire);  // 错！store用release\n```",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_020",
    "question": "（无锁队列追问）为什么不用Qt的信号槽来做线程间数据传输？",
    "tags": ["Qt", "信号槽", "无锁编程", "性能", "设计决策"],
    "difficulty": 2,
    "hint": "Qt信号槽跨线程有类型擦除/QVariant转换开销和动态内存分配，对高频场景过重；自实现可针对场景优化（零拷贝shared_ptr、控制队列满行为、加监控统计）。",
    "answer": "信号槽底层也是事件队列，但对高频数据传输有问题：\n1. 有类型擦除和QVariant转换开销\n2. 跨线程时会动态分配内存\n3. 通用设计，对高频场景过重\n\n自己实现SPSC队列的好处：\n1. 针对场景优化，零拷贝（shared_ptr）\n2. 控制队列满时的行为（丢弃旧数据而非阻塞）\n3. 方便加监控统计",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_021",
    "question": "（无锁队列追问）无锁队列会丢数据吗？怎么处理？",
    "tags": ["无锁编程", "SPSC", "数据丢失", "实时系统", "设计权衡"],
    "difficulty": 2,
    "hint": "会丢——队列满时push失败。但关键是场景允许丢帧（采集1000Hz显示30Hz，大部分帧本来不显示），保证\"最新数据能显示\"即可。不允许丢失时可用阻塞队列或可变大小队列。",
    "answer": "会，队列满了push会失败。但我们的场景允许丢帧：\n- 采集1000Hz，显示30Hz，大部分帧本来就不显示\n- 关键是保证\"最新数据能显示\"，而非\"每帧都显示\"\n- 丢弃的是中间帧，不影响实时性\n\n如果不允许丢失：\n- 可以用阻塞队列\n- 或者用可变大小的队列（但需要锁保护分配）",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_022",
    "question": "（无锁队列追问）如果有多个生产者怎么办？",
    "tags": ["无锁编程", "SPSC", "MPSC", "多生产者", "并发架构"],
    "difficulty": 2,
    "hint": "SPSC不支持多生产者，三种方案：每个生产者一个队列消费者轮询、用MPSC队列、用mutex队列（简单够用就行）。项目里每个检测模块一个队列正好是SPSC。",
    "answer": "SPSC不支持多生产者，可以：\n\n**方案1**：每个生产者一个队列，消费者轮询\n**方案2**：用MPSC（多生产者单消费者）队列\n**方案3**：用mutex保护的队列（简单，性能够用就行）\n\n我们项目是每个检测模块一个队列，正好是SPSC。",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_023",
    "question": "（无锁队列追问）怎么测试无锁队列的正确性？",
    "tags": ["无锁编程", "测试", "并发测试", "ThreadSanitizer", "压力测试"],
    "difficulty": 2,
    "hint": "三层测试：单元测试（空队列pop/满队列push/数据正确性）、并发测试（双线程跑百万次+TSan检测）、压力测试（跑24小时检查内存泄漏和崩溃）。",
    "answer": "1. **单元测试**\n   - 空队列pop返回false\n   - 满队列push返回false\n   - push后pop能取到正确数据\n\n2. **并发测试**\n   - 两个线程分别push和pop\n   - 跑百万次，检查数据完整性\n   - 用ThreadSanitizer检测数据竞争\n\n3. **压力测试**\n   - 跑24小时，检查内存泄漏和崩溃",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_024",
    "question": "（无锁队列追问）有没有现成的无锁队列库？为什么自己写？",
    "tags": ["无锁编程", "Boost", "folly", "moodycamel", "第三方库"],
    "difficulty": 1,
    "hint": "有现成的（Boost.Lockfree / folly::ProducerConsumerQueue / moodycamel::ConcurrentQueue），自己写的原因是学习目的+需求简单200行搞定+减少外部依赖。",
    "answer": "有，比如：\n- Boost.Lockfree\n- folly::ProducerConsumerQueue\n- moodycamel::ConcurrentQueue\n\n为什么自己写：\n1. 学习目的，理解原理\n2. 我们的需求简单，200行代码搞定\n3. 减少外部依赖",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_025",
    "question": "什么是false sharing？无锁队列中如何避免？",
    "tags": ["无锁编程", "false sharing", "缓存行", "alignas", "性能优化"],
    "difficulty": 3,
    "hint": "false sharing是两个变量在同一缓存行，一个CPU改其中一个导致另一个CPU的缓存行失效；解决方法是alignas(64)让head和tail各占一个缓存行。",
    "answer": "### 问题\n```cpp\n// 问题代码\nstruct BadQueue {\n    std::atomic<size_t> head_;  // 和tail_可能在同一个缓存行\n    std::atomic<size_t> tail_;  // 一个CPU改head，另一个CPU的tail缓存失效\n};\n```\n\nhead和tail如果在同一个缓存行（通常64字节），生产者修改head时会导致消费者CPU上的tail缓存行失效，反之亦然，即使它们是不同的变量。\n\n### 解决方案\n```cpp\n// 优化代码\nstruct GoodQueue {\n    alignas(64) std::atomic<size_t> head_;  // 64字节对齐\n    alignas(64) std::atomic<size_t> tail_;  // 各占一个缓存行\n};\n```\n\n通过 `alignas(64)` 让 head 和 tail 各自独占一个缓存行，消除 false sharing。",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_026",
    "question": "什么是ABA问题？SPSC队列有这个问题吗？",
    "tags": ["无锁编程", "ABA问题", "CAS", "SPSC"],
    "difficulty": 3,
    "hint": "ABA是CAS操作的陷阱：线程1读到A，线程2改成B又改回A，线程1 CAS成功但中间状态已变。SPSC没有这个问题因为head/tail只单向增长。",
    "answer": "### ABA问题场景\n比较并交换（CAS）操作中：\n1. 线程1读到A\n2. 线程2把A改成B，又改回A\n3. 线程1执行CAS，发现还是A，认为没变化\n\n### 解决方案\n- 带版本号的指针\n- Hazard Pointer\n\n### SPSC队列不受影响\n我们的SPSC没有这个问题，因为head/tail只会单向增长，不会出现\"改回去\"的情况。",
    "source": "深度问题_无锁队列.md"
  },
  {
    "id": "cpp_027",
    "question": "无锁队列有哪些优化技巧？（批量操作、容量选择）",
    "tags": ["无锁编程", "性能优化", "批量操作", "容量设计"],
    "difficulty": 2,
    "hint": "两个优化方向：批量pop减少原子操作次数；容量选2的幂用位运算代替取模，大小根据生产速率×最大消费延迟计算。",
    "answer": "### 批量操作\n```cpp\n// 单次操作\nwhile (queue.pop(item)) {\n    process(item);\n}\n\n// 批量操作，减少原子操作次数\nsize_t batch[32];\nsize_t count = queue.pop_batch(batch, 32);\nfor (size_t i = 0; i < count; i++) {\n    process(batch[i]);\n}\n```\n\n### 容量选择\n```cpp\n// 容量必须是2的幂，用位运算代替取模\nsize_t next = (head + 1) & (Capacity - 1);  // 比 % Capacity 快\n\n// 容量计算公式：\n// 根据生产者速率和消费者最大延迟计算\n// 例如：1000Hz生产，消费者最多卡100ms\n// 容量 = 1000 * 0.1 = 100，取128（2的幂）\n```\n\n太小容易满导致数据丢失，太大浪费内存。",
    "source": "深度问题_无锁队列.md"
  }
]
